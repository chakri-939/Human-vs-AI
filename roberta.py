# -*- coding: utf-8 -*-
"""Roberta.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HkpKhKHE3bIcCsJ6CE0QpKYTNW4iFFI3

<a href="https://colab.research.google.com/github/shreyamaurya029/AI-vs-Human-/blob/main/Robertawithmorefeatures.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import torch
from torch.utils.data import DataLoader, Dataset
from transformers import RobertaTokenizer,RobertaModel, RobertaForSequenceClassification, AdamW, get_scheduler
from torch import nn
from tqdm.auto import tqdm
from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score
import os

df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/traindataset.csv')

df.head(2)

# Fill missing values and ensure text is of string type
df['Text'].fillna('', inplace=True)
df['Text'] = df['Text'].astype(str)

text_column = 'Text'
label_column = 'Label'
feature_columns = ['Vocab Size', 'Avg Word Length', 'Density', 'active',
       'passive', 'noun', 'pron', 'verb', 'adj', 'adv', 'det', 'propn', 'part',
       'intj', 'punct', 'Flesch Reading Ease',
       'Gunning Fog Index', 'Perplexity' , 'Burstness']

train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)

scaler = StandardScaler()
train_df[feature_columns] = scaler.fit_transform(train_df[feature_columns])
test_df[feature_columns] = scaler.transform(test_df[feature_columns])

class CombinedDataset(Dataset):
    def __init__(self, texts, additional_features, labels, tokenizer, max_length=128):
        self.texts = texts
        self.additional_features = additional_features
        self.labels = labels
        self.tokenizer = tokenizer
        self.max_length = max_length

    def __len__(self):
        return len(self.labels)

    def __getitem__(self, idx):
        text = self.texts[idx]
        additional_features = torch.tensor(self.additional_features[idx], dtype=torch.float)
        label = torch.tensor(self.labels[idx], dtype=torch.long)

        # Tokenize the text
        encoding = self.tokenizer(text, padding='max_length', truncation=True, max_length=self.max_length, return_tensors='pt')
        input_ids = encoding['input_ids'].squeeze(0).long()
        attention_mask = encoding['attention_mask'].squeeze(0).long()

        return {
            'input_ids': input_ids,
            'attention_mask': attention_mask,
            'additional_features': additional_features,
            'labels': label
        }

class RobertaWithFeatures(nn.Module):
    def __init__(self, model_name, feature_dim, num_labels):
        super(RobertaWithFeatures, self).__init__()
        self.roberta = RobertaModel.from_pretrained(model_name)
        self.classifier = nn.Linear(self.roberta.config.hidden_size + feature_dim, num_labels)

    def forward(self, input_ids, attention_mask, additional_features, labels=None):
        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)
        last_hidden_state = outputs.last_hidden_state
        pooled_output = last_hidden_state[:, 0, :]

        combined_output = torch.cat((pooled_output, additional_features), dim=1)

        logits = self.classifier(combined_output)

        loss = None
        if labels is not None:
            loss = nn.CrossEntropyLoss()(logits, labels)

        return (loss, logits) if loss is not None else logits

tokenizer = RobertaTokenizer.from_pretrained('roberta-base')

model = RobertaWithFeatures('roberta-base', len(feature_columns), num_labels=2)
device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
model.to(device)

train_dataset = CombinedDataset(
    texts=train_df[text_column].tolist(),
    additional_features=train_df[feature_columns].values,
    labels=train_df[label_column].tolist(),
    tokenizer=tokenizer
)

test_dataset = CombinedDataset(
    texts=test_df[text_column].tolist(),
    additional_features=test_df[feature_columns].values,
    labels=test_df[label_column].tolist(),
    tokenizer=tokenizer
)

# Create dataloaders
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)

optimizer = AdamW(model.parameters(), lr=5e-5)
num_epochs = 3
num_training_steps = num_epochs * len(train_loader)
lr_scheduler = get_scheduler(name="linear", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)

model.train()
progress_bar = tqdm(range(num_training_steps))

for epoch in range(num_epochs):
    for batch in train_loader:
        batch = {k: v.to(device) for k, v in batch.items()}

        outputs = model(
            input_ids=batch['input_ids'],
            attention_mask=batch['attention_mask'],
            additional_features=batch['additional_features'],
            labels=batch['labels']
        )

        loss = outputs[0]
        loss.backward()

        optimizer.step()
        lr_scheduler.step()
        optimizer.zero_grad()
        progress_bar.update(1)

model_save_path = '/content/drive/MyDrive/Models/Roberta'
torch.save(model.state_dict(), model_save_path)
print(f"Model saved to {model_save_path}")

import numpy as np

model.eval()
predictions = []
true_labels = []

with torch.no_grad():
    for batch in test_loader:
        batch = {k: v.to(device) for k, v in batch.items()}
        outputs = model(
            input_ids=batch['input_ids'],
            attention_mask=batch['attention_mask'],
            additional_features=batch['additional_features']
        )

        logits = outputs if isinstance(outputs, torch.Tensor) else outputs[1]
        predicted_labels = torch.argmax(logits, dim=-1).cpu().numpy()

        # Ensure predicted_labels is a 1-dimensional array
        if predicted_labels.ndim == 0:
            predicted_labels = np.expand_dims(predicted_labels, axis=0)

        predictions.extend(predicted_labels)
        true_labels.extend(batch['labels'].cpu().numpy())

# Convert lists to numpy arrays for consistency
predictions = np.array(predictions)
true_labels = np.array(true_labels)

# Calculate accuracy
accuracy = accuracy_score(true_labels, predictions)

# Calculate precision
precision = precision_score(true_labels, predictions)

# Calculate recall
recall = recall_score(true_labels, predictions)

# Calculate F1-score
f1 = f1_score(true_labels, predictions)

# Generate classification report
class_report = classification_report(true_labels, predictions, target_names=['Human', 'Machine'])

# Print the metrics
print(f"Accuracy: {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall: {recall:.4f}")
print(f"F1-Score: {f1:.4f}")
print("\nClassification Report:")
print(class_report)

test_data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/testdataset.csv')

test_data.head(2)

test_data['Text'].fillna('', inplace=True)
test_data['Text'] = test_data[text_column].astype(str)

test_data[feature_columns] = scaler.transform(test_data[feature_columns])

test1_dataset = CombinedDataset(
    texts=test_data[text_column].tolist(),
    additional_features=test_data[feature_columns].values,
    labels=test_data[label_column].tolist(),
    tokenizer=tokenizer
)

# Create dataloader
test1_loader = DataLoader(test1_dataset, batch_size=16, shuffle=False)

model.eval()
predictions1 = []
true_labels1 = []

with torch.no_grad():
    for batch in test1_loader:
        batch = {k: v.to(device) for k, v in batch.items()}
        outputs = model(
            input_ids=batch['input_ids'],
            attention_mask=batch['attention_mask'],
            additional_features=batch['additional_features']
        )

        logits = outputs if isinstance(outputs, torch.Tensor) else outputs[1]
        predicted_labels = torch.argmax(logits, dim=-1).cpu().numpy()

        # Ensure predicted_labels is a 1-dimensional array
        if predicted_labels.ndim == 0:
            predicted_labels = np.expand_dims(predicted_labels, axis=0)

        predictions1.extend(predicted_labels)
        true_labels1.extend(batch['labels'].cpu().numpy())

# Convert lists to numpy arrays for consistency
predictions1 = np.array(predictions1)
true_labels1 = np.array(true_labels1)

accuracy = accuracy_score(true_labels1, predictions1)
precision = precision_score(true_labels1, predictions1)
recall = recall_score(true_labels1, predictions1)
f1 = f1_score(true_labels1, predictions1)
class_report = classification_report(true_labels1, predictions1, target_names=['Human', 'Machine'])

print(f"Test Accuracy: {accuracy:.4f}")
print(f"Test Precision: {precision:.4f}")
print(f"Test Recall: {recall:.4f}")
print(f"Test F1-Score: {f1:.4f}")
print("\nClassification Report:")
print(class_report)

from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, ConfusionMatrixDisplay, RocCurveDisplay
import matplotlib.pyplot as plt
cm = confusion_matrix(true_labels1, predictions1)
ConfusionMatrixDisplay(cm, display_labels=['Human', 'Machine']).plot()
plt.title('Confusion Matrix')
plt.show()

# AUC-ROC Curve
fpr, tpr, _ = roc_curve(true_labels1, predictions1, pos_label=1)
roc_auc = roc_auc_score(true_labels1, predictions1)

print(roc_auc)
plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.show()